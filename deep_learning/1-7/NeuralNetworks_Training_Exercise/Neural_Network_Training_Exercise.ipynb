{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMWT24IcCq1N"
      },
      "source": [
        "# Problem Statement: **Training in Agricultural Company**\n",
        "\n",
        "### In this chapter, you’ll explore the foundational aspects of training neural networks in AI-oriented Agricultural company. You’ll work as an AI engineer to train models that solve critical challenges in different domains. Along the way, you’ll learn about gradient descent, batch processing, and training neural networks from scratch.\n",
        "\n",
        "References:\n",
        "* Column Stack (Numpy) [link](https://numpy.org/doc/stable/reference/generated/numpy.column_stack.html)\n",
        "\n",
        "* PyTorch Tensors (PyTorch) [link](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)\n",
        "\n",
        "* Sequential (PyTorch) [link](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7qTZ-o7DRTP"
      },
      "source": [
        "Imports and CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVRQzxnKCbRL",
        "outputId": "00ad97d5-4ddf-4999-d571-d98e79464cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRPCoIeNOAPw"
      },
      "source": [
        "### **Task1: Predicting Equipment Costs**\n",
        "\n",
        "The AI Agriculture Company is developing a tool to predict the cost of manufacturing its new agricultural equipment. The cost is directly proportional to the square of the material used. Your task is to compute and predict the cost, and debug the gradients of the implemented backpropagation process.\n",
        "\n",
        "Use when required: $$ f(x) = x^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDYY9uleUxBC"
      },
      "source": [
        "**Step1:** Define the Problem\n",
        "\n",
        "Assume the material required is represented as a single feature: **material_amount**. For simplicity:\n",
        "\n",
        "* **Input:** material_amount (a tensor of size (1, 1)) — e.g., 5 units of material.\n",
        "* **Target cost:** material_amount ** 2 — the cost of producing the equipment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JIih0kRoViAx"
      },
      "outputs": [],
      "source": [
        "# Material amount as input (e.g., 5 units)\n",
        "material_amount=torch.tensor([[5.0]],requires_grad=False)\n",
        "# Target cost (cost = material_amount ** 2)\n",
        "target_cost=material_amount**2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbRa2fmNVic8"
      },
      "source": [
        "**Step2:** Set Up the Model\n",
        "\n",
        "Use a single-layer linear model to predict the cost. The model should:\n",
        "\n",
        "* Take material_amount as input.\n",
        "* Output the predicted cost (scalar)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x2PbKdlmV5ir"
      },
      "outputs": [],
      "source": [
        "# Start with random weights and zero biases\n",
        "w1=torch.tensor([[0.5]],requires_grad=True)\n",
        "bias=torch.tensor([[0.0]],requires_grad=True)\n",
        "\n",
        "predicted_cost=torch.matmul(w1,material_amount)+bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4mPVdW0V5_9"
      },
      "source": [
        "**Step3:** Compute Loss\n",
        "\n",
        "Use Mean Squared Error **(MSE)** to calculate the loss between the predicted and actual costs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IMRhR4-5WJgS"
      },
      "outputs": [],
      "source": [
        "# Loss function: Mean Squared Error (MSE)\n",
        " \n",
        "mse=torch.mean((predicted_cost-target_cost)**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3KtHjd2WJ7V"
      },
      "source": [
        "**Step4:** Backpropagation\n",
        "\n",
        "* Write the gradient descent process step-by-step.\n",
        "* Manually compute the gradients of the loss with respect to the model's weights and biases using the chain rule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ury9YtJbxjxa"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2378633430.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    grad_bias=\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Calculate the gradient of the loss w.r.t. predicted_cost\n",
        "grad_predicted_cost=2(predicted_cost-target_cost)/target_cost.size()\n",
        "# Calculate the gradient of predicted_cost w.r.t. weight and bias\n",
        "grad_weight=2(material_amount)/target_cost.size()\n",
        "grad_bias="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQkAqhsmWY1-"
      },
      "source": [
        "**Step5:** Verify Gradients\n",
        "\n",
        "Use **torch.autograd** to compute gradients automatically and compare them with your manual calculations.\n",
        "\n",
        "You can use **allclose** to check whether all elements of two tensors are approximately equal, within a specified tolerance.\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.allclose.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CWS7RR2eXIC1"
      },
      "outputs": [],
      "source": [
        "# Code Here\n",
        "mse.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-225.]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w1.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U56K7C-qQ5_L"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owGLtVZQTRsG"
      },
      "source": [
        "### **Task2: Optimizing Equipment Production with Neural Networks**\n",
        "\n",
        "The AI Agriculture Company wants to predict the efficiency of manufacturing equipment based on two input features:\n",
        "\n",
        "* Weekly hours spent on machine maintenance\n",
        "* Weekly hours spent on training factory workers.\n",
        "\n",
        "The company believes these two factors significantly impact production efficiency, which is represented as a score between 0 and 1. Your task is to build and train a simple neural network to predict this efficiency score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObFXxToqZudV"
      },
      "source": [
        "**Step 1:** Dataset Details\n",
        "\n",
        "Simulate a dataset with the following properties:\n",
        "\n",
        "* Feature 1: Machine Maintenance Hours (range: 5 to 50 hours).\n",
        "* Feature 2: Training Hours for Workers (range: 2 to 20 hours).\n",
        "* Target Output: Efficiency score calculated as:\n",
        "\n",
        "$$ Efficiency Score= (0.4⋅Maintenance Hours+0.6⋅Training Hours)/5$$\n",
        "​\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uhIRf13wTiFb"
      },
      "outputs": [],
      "source": [
        "# Complete the code here\n",
        "np.random.seed(42)\n",
        "machine_maintenance_hours =np.random.uniform(5,50,500)   # Maintenance hours\n",
        "training_hours =np.random.uniform(2,20,500)              # Training hours\n",
        "efficiency_score =(0.4*machine_maintenance_hours+0.6*training_hours)/5   # Efficiency score\n",
        "\n",
        "# Combine into a dataset\n",
        "x = np.column_stack((machine_maintenance_hours, training_hours))\n",
        "y = efficiency_score.reshape(-1, 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8z-ELN0aIua"
      },
      "source": [
        "**Step 2**: Split the dataset into training (80%) and validation (20%) sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aRFzPKFdaajZ"
      },
      "outputs": [],
      "source": [
        "# Code Here\n",
        "x_train,y_train,x_val,y_val=train_test_split(x,y,test_size=80,random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHskK6xHabGi"
      },
      "source": [
        "**Step3:** Normalize input features to improve training stability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0AfJlpOparCh"
      },
      "outputs": [],
      "source": [
        "#X_train, X_val, y_train, y_val = # Code Here\n",
        "scaler=MinMaxScaler()\n",
        "x=scaler.fit_transform(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PDGeXcisuvgm"
      },
      "outputs": [],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(x_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QTYqeJra68l"
      },
      "source": [
        "**Step4:** Define a neural network with the following structure:\n",
        "\n",
        "* Input Layer: 2 neurons (for the two input features).\n",
        "* Hidden Layer: 5 neurons with ReLU activation.\n",
        "* Output Layer: 1 neuron with sigmoid activation (to output a value between 0 and 1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uXr1hLVwa0wL"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 5),  # 2 input features, 5 hidden neurons\n",
        "    nn.ReLU(),        # ReLU activation\n",
        "    nn.Linear(5, 1),  # 1 output neuron\n",
        "    nn.Sigmoid()      # Sigmoid activation for efficiency score\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network=nn.Sequential(\n",
        "             nn.Linear(2, 5),  # 2 input features, 5 hidden neurons\n",
        "             nn.ReLU(),        # ReLU activation\n",
        "             nn.Linear(5, 1),  # 1 output neuron\n",
        "             nn.Sigmoid()  \n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "device='cuda'\n",
        "model=Classifier().to(device)\n",
        "\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.01)\n",
        "\n",
        "loss_fn=nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvJP8mjca8EP"
      },
      "source": [
        "**Step5**: Train the network using:\n",
        "\n",
        "* **Optimizers**: SGD.\n",
        "* **Epochs**: 200.\n",
        "* **Learning Rates**: 0.01."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "s9tmzV-IbDgR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nande\\.conda\\envs\\myenv_cb_dl\\lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([80, 2])) that is different to the input size (torch.Size([420, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (420) must match the size of tensor b (80) at non-singleton dimension 0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m y_train\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m predicted\u001b[38;5;241m=\u001b[39mmodel(x_train)\n\u001b[1;32m---> 18\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\Users\\nande\\.conda\\envs\\myenv_cb_dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\nande\\.conda\\envs\\myenv_cb_dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nande\\.conda\\envs\\myenv_cb_dl\\lib\\site-packages\\torch\\nn\\modules\\loss.py:538\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\nande\\.conda\\envs\\myenv_cb_dl\\lib\\site-packages\\torch\\nn\\functional.py:3383\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3381\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3383\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
            "File \u001b[1;32mc:\\Users\\nande\\.conda\\envs\\myenv_cb_dl\\lib\\site-packages\\torch\\functional.py:77\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (420) must match the size of tensor b (80) at non-singleton dimension 0"
          ]
        }
      ],
      "source": [
        "# def train_model(model, loss_fn, optimizer, X, y, X_val, y_val, epochs):\n",
        "#   # Code Here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 6: Train and evaluate the model\n",
        "epochs=200\n",
        "learning_rate =0.01\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  x_train=x_train.to(device)\n",
        "  y_train=y_train.to(device)\n",
        "  \n",
        "  predicted=model(x_train)\n",
        "  loss=loss_fn(predicted,y_train)\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  if epoch%10==0:\n",
        "    print(f\"Epoch:{epoch+1},Loss:{loss.item():.4f}\")\n",
        "    \n",
        "  \n",
        "  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w6lR90ebD_i"
      },
      "source": [
        "**Step6:**  Plot and analyze the convergence curves for training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psR_lEurbNIp"
      },
      "outputs": [],
      "source": [
        "# Code Here\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\", linestyle=\"--\")\n",
        "plt.title(\"Loss Convergence\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aa7BLa95gBY"
      },
      "source": [
        "**Bonus:** Modify epochs to 500 and learning rate to 0.05 and analyse the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjL-YESATyt_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrJ4LHZiTz5a"
      },
      "source": [
        "### **Task4: Predicting Crop Yield in AgroTech**\n",
        "\n",
        "In AgroTech, an agriculture-focused town, farmers rely on AI systems to predict crop yields based on weather and soil data.\n",
        "\n",
        "Your task is to build and train a neural network to predict Crop Yield (tons/ha) using features from the provided dataset **(agriculture_dataset_codebasics_DL.csv)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOcZzq94iTCA"
      },
      "source": [
        "**Dataset Overview**\n",
        "\n",
        "The agriculture_dataset.csv file contains the following features:\n",
        "\n",
        "* Temperature (C): Average temperature during the growing season.\n",
        "\n",
        "* Rainfall (mm): Total rainfall during the growing season.\n",
        "\n",
        "* Soil_pH: Soil acidity (range: 0-14).\n",
        "\n",
        "* Nitrogen (mg/kg): Nitrogen content in the soil.\n",
        "\n",
        "* Irrigation_Hours: Total hours of irrigation during the growing season.\n",
        "\n",
        "* Fertilizer_Usage (kg/ha): Total fertilizer used per hectare.\n",
        "\n",
        "* Crop_Yield (tons/ha): Target variable representing the crop yield."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFGxLGhiir-9"
      },
      "source": [
        "**Goal**\n",
        "\n",
        "Train a neural network to predict the crop yield using Batch Gradient Descent, Mini-Batch Gradient Descent, and Stochastic Gradient Descent.\n",
        "\n",
        "Compare their performance by plotting loss convergence over epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrxibUQ5iz7w"
      },
      "source": [
        "**Step 1:** Load and split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aiPmoJGHi1jb"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df=pd.read_csv(\"agriculture_dataset_codebasics_DL.csv\")\n",
        "\n",
        "# Split data into features and target\n",
        "df_features = df.drop('Crop Yield (tons/ha)', axis=1)\n",
        "df_target=df['Crop Yield (tons/ha)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature (C)</th>\n",
              "      <th>Rainfall (mm)</th>\n",
              "      <th>Soil pH</th>\n",
              "      <th>Nitrogen (mg/kg)</th>\n",
              "      <th>Irrigation Hours</th>\n",
              "      <th>Fertilizer Usage (kg/ha)</th>\n",
              "      <th>Crop Yield (tons/ha)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>100</td>\n",
              "      <td>6.5</td>\n",
              "      <td>40</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>200</td>\n",
              "      <td>6.8</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>60</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>150</td>\n",
              "      <td>7.0</td>\n",
              "      <td>60</td>\n",
              "      <td>12</td>\n",
              "      <td>70</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>80</td>\n",
              "      <td>6.4</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>40</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>120</td>\n",
              "      <td>6.6</td>\n",
              "      <td>45</td>\n",
              "      <td>9</td>\n",
              "      <td>55</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>27</td>\n",
              "      <td>300</td>\n",
              "      <td>7.1</td>\n",
              "      <td>70</td>\n",
              "      <td>14</td>\n",
              "      <td>80</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>29</td>\n",
              "      <td>250</td>\n",
              "      <td>7.2</td>\n",
              "      <td>65</td>\n",
              "      <td>13</td>\n",
              "      <td>75</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>23</td>\n",
              "      <td>100</td>\n",
              "      <td>6.7</td>\n",
              "      <td>35</td>\n",
              "      <td>7</td>\n",
              "      <td>45</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>26</td>\n",
              "      <td>180</td>\n",
              "      <td>6.9</td>\n",
              "      <td>55</td>\n",
              "      <td>11</td>\n",
              "      <td>65</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>30</td>\n",
              "      <td>270</td>\n",
              "      <td>7.3</td>\n",
              "      <td>75</td>\n",
              "      <td>15</td>\n",
              "      <td>85</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Temperature (C)  Rainfall (mm)  Soil pH  Nitrogen (mg/kg)  \\\n",
              "0               22            100      6.5                40   \n",
              "1               25            200      6.8                50   \n",
              "2               28            150      7.0                60   \n",
              "3               21             80      6.4                30   \n",
              "4               24            120      6.6                45   \n",
              "5               27            300      7.1                70   \n",
              "6               29            250      7.2                65   \n",
              "7               23            100      6.7                35   \n",
              "8               26            180      6.9                55   \n",
              "9               30            270      7.3                75   \n",
              "\n",
              "   Irrigation Hours  Fertilizer Usage (kg/ha)  Crop Yield (tons/ha)  \n",
              "0                 8                        50                   2.5  \n",
              "1                10                        60                   3.0  \n",
              "2                12                        70                   3.5  \n",
              "3                 6                        40                   2.2  \n",
              "4                 9                        55                   2.8  \n",
              "5                14                        80                   4.0  \n",
              "6                13                        75                   3.8  \n",
              "7                 7                        45                   2.4  \n",
              "8                11                        65                   3.2  \n",
              "9                15                        85                   4.2  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWuxNl5ii2IF"
      },
      "source": [
        "**Step 2:** Normalize the input features to a range of 0-1 and perform an **80%-20%** train-validation split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-zCs0SbSi5Az"
      },
      "outputs": [],
      "source": [
        "# Code\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler=MinMaxScaler()\n",
        "\n",
        "df_features_norm=scaler.fit_transform(df_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,y_train,x_test,y_test=train_test_split(df_features_norm,df_target,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4    2.8\n",
              "2    3.5\n",
              "3    2.2\n",
              "8    3.2\n",
              "1    3.0\n",
              "0    2.5\n",
              "7    2.4\n",
              "5    4.0\n",
              "Name: Crop Yield (tons/ha), dtype: float64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZfARwFEbv9_h"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not determine the shape of object type 'Series'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      4\u001b[0m x_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 5\u001b[0m y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mValueError\u001b[0m: could not determine the shape of object type 'Series'"
          ]
        }
      ],
      "source": [
        "# Convert data to PyTorch Tensors\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d3pW6ZGi6X5"
      },
      "source": [
        "**Step 3:** Define a neural network architecture\n",
        "\n",
        "**Input:** 6 features (Temperature, Rainfall, Soil pH, Nitrogen, Irrigation Hours, Fertilizer Usage).\n",
        "\n",
        "**Hidden Layer:** 10 neurons with ReLU activation.\n",
        "\n",
        "**Output:** 1 neuron with linear activation (for regression)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "anJo6ifrkI7-"
      },
      "outputs": [],
      "source": [
        "class ClothsClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network=nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28,128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,10)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rcfk3Y3kJsX"
      },
      "source": [
        "**Step 4:** Train the network using\n",
        "\n",
        "Batch Gradient Descent (GD):Update weights after processing the entire dataset.\n",
        "\n",
        "Mini-Batch Gradient Descent: Update weights after processing batches of size 16.\n",
        "\n",
        "Stochastic Gradient Descent (SGD): Update weights after every data point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytTSQWLWkU_A"
      },
      "outputs": [],
      "source": [
        "# Training function for different GD methods\n",
        "def train_model(optimizer, X, y, epochs=50, batch_size=None):\n",
        "    optimizer=optim.GD(model.parameters())\n",
        "    \n",
        "    for epochs in range(epoch):\n",
        "        predicted=model()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Train the model using Batch GD\n",
        "\n",
        "\n",
        "# Train the model using Mini-Batch GD\n",
        "\n",
        "\n",
        "# Train the model using Stochastic GD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrVyXVFlkaKv"
      },
      "source": [
        "**Step 5:** Plot the loss over epochs for each method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbNfMhYikeyC"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses_batch, label='Batch GD', marker='o')\n",
        "plt.plot(losses_mini_batch, label='Mini-Batch GD', marker='x')\n",
        "plt.plot(losses_sgd, label='Stochastic GD', marker='^')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Gradient Descent Strategies: Loss Convergence')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl0hir7okfXC"
      },
      "source": [
        "**Step 6:** Evaluate the model's Mean Squared Error (MSE) on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwhsjoxskknr"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "# Code Here"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv_cb_dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
