{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(training_data,batch_size=64)\n",
    "test_loader=DataLoader(test_data,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for images,labels in train_loader:\n",
    "    print(images.shape,labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(images[0].squeeze(),cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=(\"cuda\" if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available\n",
    "        else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClothsClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ClothsClassifier().to(device)\n",
    "# optimizer=optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 0, Loss: 2.3205\n",
      "Epoch: 1, Batch: 100, Loss: 0.7905\n",
      "Epoch: 1, Batch: 200, Loss: 0.4833\n",
      "Epoch: 1, Batch: 300, Loss: 0.6519\n",
      "Epoch: 1, Batch: 400, Loss: 0.5180\n",
      "Epoch: 1, Batch: 500, Loss: 0.4625\n",
      "Epoch: 1, Batch: 600, Loss: 0.4218\n",
      "Epoch: 1, Batch: 700, Loss: 0.6251\n",
      "Epoch: 1, Batch: 800, Loss: 0.5697\n",
      "Epoch: 1, Batch: 900, Loss: 0.4991\n",
      "Epoch: 2, Batch: 0, Loss: 0.3276\n",
      "Epoch: 2, Batch: 100, Loss: 0.4024\n",
      "Epoch: 2, Batch: 200, Loss: 0.3200\n",
      "Epoch: 2, Batch: 300, Loss: 0.4667\n",
      "Epoch: 2, Batch: 400, Loss: 0.4507\n",
      "Epoch: 2, Batch: 500, Loss: 0.3885\n",
      "Epoch: 2, Batch: 600, Loss: 0.3587\n",
      "Epoch: 2, Batch: 700, Loss: 0.5796\n",
      "Epoch: 2, Batch: 800, Loss: 0.5149\n",
      "Epoch: 2, Batch: 900, Loss: 0.4928\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):  # Epoch loop\n",
    "    for batch, (images, labels) in enumerate(train_loader):  # Batch loop\n",
    "        # Move data to the specified device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Weight update\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print progress\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch + 1}, Batch: {batch}, Loss: {loss.item():.4f}\")\n",
    "#SGD without momentum 2.3==>2.02\n",
    "#SGD with momentum 2.3==>0.65 \n",
    "#adam 2.3==>0.49\n",
    "#hence this is called optimisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_predicted=[]\n",
    "all_labels=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images,labels in test_loader:\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        outputs=model(images)\n",
    "        \n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predicted.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 2, 1, 1, 6]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 2, 1, 1, 6]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predicted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report=classification_report(all_labels,all_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      1000\n",
      "           1       0.95      0.97      0.96      1000\n",
      "           2       0.85      0.60      0.70      1000\n",
      "           3       0.84      0.88      0.86      1000\n",
      "           4       0.65      0.88      0.75      1000\n",
      "           5       0.95      0.93      0.94      1000\n",
      "           6       0.72      0.52      0.61      1000\n",
      "           7       0.88      0.96      0.92      1000\n",
      "           8       0.91      0.98      0.94      1000\n",
      "           9       0.98      0.91      0.94      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.84     10000\n",
      "weighted avg       0.85      0.85      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_cb_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
