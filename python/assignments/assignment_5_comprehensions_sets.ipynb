{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c753c4",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style=\"color:blue\">Codebasics Python Course: Exercise - Comprehensions, Sets</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbb5a6-f24e-4f67-9d8d-2ee65a7bdadc",
   "metadata": {},
   "source": [
    "**Loki** shared a few ad-hoc tasks that his team is working on across different projects at **AtliQ**, and now you will be helping him with them.\n",
    "\n",
    "<img src=\"https://files.codebasics.io/55188/avatar/lokhi.png\" width=\"10%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe45535-374e-4d8c-8427-ac690ac0c178",
   "metadata": {},
   "source": [
    "### Task 1: Inventory Analysis for E-Commerce Client\n",
    "\n",
    "**AtliQ**, a service-based software company, is supporting an e-commerce client in analyzing their inventory data. The client wants to gain insights into the range of product categories available in their inventory. Your task, as part of the AtliQ team, is to identify and print all the unique product categories from a list of product records provided.\n",
    "\n",
    "You will be given a dataset containing product details, and your goal is to extract and display the distinct product categories present in the inventory.\n",
    "\n",
    "**Expected Output**\n",
    "\n",
    "\n",
    "Unique Product Categories:\n",
    "\n",
    "- Electronics\n",
    "- Apparel\n",
    "- Home Appliances\n",
    "- Literatureure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f1d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"product_name\": \"Laptop\", \"category\": \"Electronics\", \"price\": 1200},\n",
    "    {\"product_name\": \"Jeans\", \"category\": \"Apparel\", \"price\": 40},\n",
    "    {\"product_name\": \"Coffee Maker\", \"category\": \"Home Appliances\", \"price\": 80},\n",
    "    {\"product_name\": \"Smartphone\", \"category\": \"Electronics\", \"price\": 999},\n",
    "    {\"product_name\": \"Jacket\", \"category\": \"Apparel\", \"price\": 60},\n",
    "    {\"product_name\": \"Blender\", \"category\": \"Home Appliances\", \"price\": 150},\n",
    "    {\"product_name\": \"Book\", \"category\": \"Literature\", \"price\": 15}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bb1f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Apparel\n",
      "-Electronics\n",
      "-Home Appliances\n",
      "-Literature\n"
     ]
    }
   ],
   "source": [
    "# write your \n",
    "unique_categories={product[\"category\"] for product in products}\n",
    "\n",
    "for cat in unique_categories:\n",
    "    print(f\"-{cat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845798d2-81c1-47c9-a6ee-780e0407f2c2",
   "metadata": {},
   "source": [
    "### Task 2: Audience Analysis for Music Festival Organizer\n",
    "\n",
    "As the other team got occupied with an urgent task, you have been asked to assist another client on an ad-hoc basis. The client is a music festival organizer looking to optimize event planning and marketing strategies by understanding audience overlap between concerts. \n",
    "\n",
    "Your task is to help analyze the data and:\n",
    "\n",
    "1. Identify unique attendees for each concert.\n",
    "2. Find common attendees across the concerts.\n",
    "\n",
    "The attendee data is provided in the next cell. Use set operations to complete the analysis and print a summary of the results.\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "Unique Attendees for Each Concert:\n",
    "- Concert A Only: {'Charlie'}\n",
    "- Concert B Only: {'Eve'}\n",
    "- Concert C Only: {'George', 'Elle'}\n",
    "\n",
    "Common Attendees Between All Concerts: {'Bob'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fc6ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concert_a_attendees = {\"Alice\", \"Bob\", \"Charlie\", \"Diana\"}\n",
    "concert_b_attendees = {\"Bob\", \"Diana\", \"Eve\", \"Frank\"}\n",
    "concert_c_attendees = {\"Alice\", \"George\", \"Elle\", \"Frank\",\"Bob\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13426f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "a=set(concert_a_attendees)\n",
    "b=set(concert_b_attendees)\n",
    "c=set(concert_c_attendees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aec6b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Attendees for Each Concert \n",
      " -Concert a only{'Charlie'} \n",
      " -Concert b only {'Eve'} \n",
      " -Concert c only {'George', 'Elle'}\n",
      "Comman Attendees Between all concerts:{'Bob'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Unique Attendees for Each Concert \\n -Concert a only{a-b-c} \\n -Concert b only {b-a-c} \\n -Concert c only {c-a-b}\")\n",
    "\n",
    "print(f\"Comman Attendees Between all concerts:{a.intersection(b).intersection(c)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fdaa64",
   "metadata": {},
   "source": [
    "### Task 3: Temperature Trend Analysis\n",
    "\n",
    "In this task, you've been assigned to help a client who is analyzing daily temperature records for a month to understand temperature trends. The client is particularly interested in identifying the records when the temperature exceeded **70°F.**\n",
    "\n",
    "Your responsibility is to analyze this dataset and extract the records where the maximum temperature was above 70°F. \n",
    "\n",
    "Display the filtered temperatures.\n",
    "\n",
    "The temperature data is given in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c229a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_temperatures = [68, 71, 74, 69, 70, 71, 68, 73, 72, 71, 70, 74, 72, 68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0dc59a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71, 74, 71, 73, 72, 71, 74, 72]\n",
      "[71, 74, 71, 73, 72, 71, 74, 72]\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "\n",
    "new_temp=[]\n",
    "\n",
    "for temp in daily_temperatures:\n",
    "    if temp>70:\n",
    "        new_temp.append(temp)\n",
    "    else:\n",
    "        pass\n",
    "print(new_temp)\n",
    "\n",
    "\n",
    "filtered_temperatures=[ temp for temp in daily_temperatures if temp>70]\n",
    "\n",
    "#new_temp_2=[temp if temp>70 else pass for temp in daily_temperature]\n",
    "\n",
    "print(filtered_temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbcb92",
   "metadata": {},
   "source": [
    "### Task 4: Identifying Unique Temperatures\n",
    "\n",
    "The client wants to find all unique temperature values recorded over a month. Your task is to use set comprehension to extract and print the unique temperatures from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2bef5837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_temperatures are {72, 73, 74, 71}\n",
      "filtered_temperatures are [71, 74, 71, 73, 72, 71, 74, 72]\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "new_temp_set=set(new_temp_2)\n",
    "# print(new_temp_set)\n",
    "#creates set \n",
    "\n",
    "temp_set=[]\n",
    "unique_temperatures={temp for temp in new_temp_2 }\n",
    "#uses set comprehension\n",
    "\n",
    "print(f\"unique_temperatures are {unique_temperatures}\")\n",
    "print(f\"filtered_temperatures are {filtered_temperatures}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107f9b4",
   "metadata": {},
   "source": [
    "### Task 5: Temperature Frequency Analysis\n",
    "\n",
    "Identify how often each temperature was recorded over a month. Your task is to use dictionary comprehension to count and print the occurrences of each temperature in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02f5d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{72: 2, 73: 1, 74: 2, 71: 3}\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "temperature_count = {temp: filtered_temperatures.count(temp) for temp in unique_temperatures}\n",
    "\n",
    "\n",
    "temperature_count={temp:filtered_temperatures.count(temp) for temp in unique_temperatures}\n",
    "\n",
    "print(temperature_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a66b697",
   "metadata": {},
   "source": [
    "### Task 6: Social Media Engagement Analysis\n",
    "\n",
    "You are tasked with helping a client analyze their social media data to identify trending hashtags and measure user engagement. Specifically, you need to extract posts that have received more than 100 likes. Your task is to filter these posts and store them in a variable called popular_posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e4eef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [\n",
    "    {\"content\": \"Loving the sunny weather today! #sunny #happy\", \"likes\": 120},\n",
    "    {\"content\": \"Nothing beats a beach day. #beachday #sunny\", \"likes\": 350},\n",
    "    {\"content\": \"A rainy day at home. #rainy #lazyday\", \"likes\": 75},\n",
    "    {\"content\": \"Best coffee in town. #coffeelove #morning\", \"likes\": 180},\n",
    "    {\"content\": \"Can't wait for the weekend. #weekend #party\", \"likes\": 90}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4adcae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_posts={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e131288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The popular post with >100 likes are :\n",
      "-Loving the sunny weather today! #sunny #happy\n",
      "-Nothing beats a beach day. #beachday #sunny\n",
      "-Best coffee in town. #coffeelove #morning\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "popular_posts={ post['content']:post['likes'] for post in posts if post['likes']>100}\n",
    "\n",
    "print(f\"The popular post with >100 likes are :\")\n",
    "for post in popular_posts:\n",
    "    print(f\"-{post}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04d6c8",
   "metadata": {},
   "source": [
    "### Task 7: Unique Hashtag Extraction\n",
    "Building on the previous task, now that you've identified the popular posts, the client wants to understand which hashtags are being used across these posts. Your task is to extract all unique hashtags from the popular posts.\n",
    "\n",
    "The list of popular posts is provided from the previous task.\n",
    "\n",
    "Tip 💡: Use set comprehension to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6e9e750e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loving the sunny weather today! #sunny #happy': 120,\n",
       " 'Nothing beats a beach day. #beachday #sunny': 350,\n",
       " 'Best coffee in town. #coffeelove #morning': 180}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a6819836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#beachday', '#coffeelove', '#happy', '#morning', '#sunny'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = set(tag for post in popular_posts for tag in post.split() if tag.startswith('#'))\n",
    "hashtags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2ddce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eca72892",
   "metadata": {},
   "source": [
    "### Task 8: Hashtag Frequency Analysis\n",
    "\n",
    "In this task, the client wants to understand how frequently each hashtag appears in the popular posts. Your task is to count the occurrences of each hashtag from the popular posts using dictionary comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e4f76700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#happy': 1, '#sunny': 2, '#coffeelove': 1, '#morning': 1, '#beachday': 1}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "hashtag_frequency = {tag: sum(tag in post for post in popular_posts) for tag in hashtags}\n",
    "hashtag_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b3eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
